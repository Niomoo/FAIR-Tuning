{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some random imorts\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import glob\n",
    "from os.path import basename, dirname,join\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import functions for bootstrap tests\n",
    "from bootstrap_TCGA_improvement_test import CV_bootstrap_improvement_test\n",
    "from bootstrap_TCGA_bias_test import CV_bootstrap_bias_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example CSV files for the results\n",
    "\n",
    "    Each pd.DataFrame contains the following columns:\n",
    "        * sens_attr: sensitive attributes\n",
    "        * prob: model probabilities\n",
    "        * label: ground truth labels\n",
    "        * pred:  model predictions\n",
    "        * [A slide ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_csvs    = [f'bootstrap_example_csvs/baseline/inference_results_fold{i}.csv' for i in range(4)]\n",
    "corrected_csvs   = [f'bootstrap_example_csvs/corrected/inference_results_fold{i}.csv' for i in range(4)]\n",
    "\n",
    "dfs_baseline = [pd.read_csv(csv) for csv in baseline_csvs]\n",
    "dfs_corrected = [pd.read_csv(csv) for csv in corrected_csvs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>logits</th>\n",
       "      <th>prob</th>\n",
       "      <th>file</th>\n",
       "      <th>sens_attr</th>\n",
       "      <th>subjIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.701804</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>M</td>\n",
       "      <td>G-002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.957226</td>\n",
       "      <td>0.123768</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>F</td>\n",
       "      <td>G-005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.703713</td>\n",
       "      <td>0.024040</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>F</td>\n",
       "      <td>G-014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621319</td>\n",
       "      <td>0.349482</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>F</td>\n",
       "      <td>G-019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.343101</td>\n",
       "      <td>0.912384</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>F</td>\n",
       "      <td>G-021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label    logits      prob  \\\n",
       "0           0    0.0  0.855903  0.701804   \n",
       "1           1    1.0 -1.957226  0.123768   \n",
       "2           2    1.0 -3.703713  0.024040   \n",
       "3           3    0.0 -0.621319  0.349482   \n",
       "4           4    1.0  2.343101  0.912384   \n",
       "\n",
       "                                                file sens_attr subjIDs  \n",
       "0  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         M   G-002  \n",
       "1  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         F   G-005  \n",
       "2  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         F   G-014  \n",
       "3  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         F   G-019  \n",
       "4  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         F   G-021  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_baseline[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add binary predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "for df in dfs_baseline:\n",
    "    df['pred'] = df['prob'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "for df in dfs_corrected:\n",
    "    df['pred'] = df['prob'].apply(lambda x: 1 if x > 0.5 else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows without sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_baseline = [df.loc[~df['sens_attr'].isna()] for df in dfs_baseline]\n",
    "dfs_corrected = [df.loc[~df['sens_attr'].isna()] for df in dfs_corrected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for significant bias\n",
    "        df_p_worse:     If the underpriviledged group has lower performance than the priviledged group (for each  performance metric)\n",
    "        df_p_better:    If the underpriviledged group has HIGHER performance than the priviledged group (for each  performance metric)\n",
    "        fairResult:     the original performance & fairnes metrics\n",
    "        df_CI:          The confidence interval of the performance & fairnes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:19<00:00, 52.41it/s]\n",
      "100%|██████████| 1000/1000 [00:18<00:00, 55.08it/s]\n",
      "100%|██████████| 1000/1000 [00:19<00:00, 50.78it/s]\n",
      "100%|██████████| 1000/1000 [00:17<00:00, 56.08it/s]\n"
     ]
    }
   ],
   "source": [
    "aggregate_method = 'concatenate' # can also be 'concatenate'\n",
    "n_bootstrap=1000 ## should be more than 1000 for valid analysis\n",
    "privileged_group = None # if given, fix the priviledged group. If None, the priviledged group will be the group with the best performance (may be different for each metric)\n",
    "df_p_worse_baseline, df_p_better_baseline, fairResult_baseline, df_CI_baseline =  CV_bootstrap_bias_test(\n",
    "    dfs_baseline, privileged_group=privileged_group, n_bootstrap=n_bootstrap,aggregate_method=aggregate_method)\n",
    "df_p_worse_corrected, df_p_better_corrected, fairResult_corrected, df_CI_corrected =  CV_bootstrap_bias_test(\n",
    "    dfs_corrected, privileged_group=privileged_group, n_bootstrap=n_bootstrap,aggregate_method=aggregate_method)\n",
    "# def CV_bootstrap_improvement_test(\n",
    "#     dfs_baseline, dfs_corrected, privileged_group=None, n_bootstrap=1000,aggregate_method='fisher',add_perf_difference=args.add_perf_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PQD</th>\n",
       "      <th>PQD(class)</th>\n",
       "      <th>EPPV</th>\n",
       "      <th>ENPV</th>\n",
       "      <th>DPM(Positive)</th>\n",
       "      <th>DPM(Negative)</th>\n",
       "      <th>EOM(Positive)</th>\n",
       "      <th>EOM(Negative)</th>\n",
       "      <th>AUCRatio</th>\n",
       "      <th>EOpp0</th>\n",
       "      <th>...</th>\n",
       "      <th>PPV_diff</th>\n",
       "      <th>NPV_diff</th>\n",
       "      <th>PR_diff</th>\n",
       "      <th>NR_diff</th>\n",
       "      <th>BAcc_diff</th>\n",
       "      <th>FPR_diff</th>\n",
       "      <th>FNR_diff</th>\n",
       "      <th>OverAllAcc_diff</th>\n",
       "      <th>OverAllAUC_diff</th>\n",
       "      <th>TOTALACC_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pval</th>\n",
       "      <td>0.211</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PQD  PQD(class)   EPPV   ENPV  DPM(Positive)  DPM(Negative)  \\\n",
       "pval  0.211       0.211  0.265  0.486          0.897          0.892   \n",
       "\n",
       "      EOM(Positive)  EOM(Negative)  AUCRatio  EOpp0  ...  PPV_diff  NPV_diff  \\\n",
       "pval          0.462          0.269     0.981  0.275  ...     0.267     0.482   \n",
       "\n",
       "      PR_diff  NR_diff  BAcc_diff  FPR_diff  FNR_diff  OverAllAcc_diff  \\\n",
       "pval    0.891    0.891      0.208     0.725     0.519              1.0   \n",
       "\n",
       "      OverAllAUC_diff  TOTALACC_diff  \n",
       "pval              1.0          0.212  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## If you use fisher, there will be p-values for each fold, plus a combined p-value\n",
    "df_p_worse_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for significant improvement\n",
    "        df_p_better: pd.DataFrame, the p-values for significant improvement\n",
    "        df_p_worse: pd.DataFrame, the p-values for significant worsening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:53<00:00, 18.77it/s]\n",
      "/home/FAIR-Tuning/bootstrap_significant_test/bootstrap_TCGA_improvement_test.py:242: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  bootstrap_values = df_improvement_bootstrap[col].loc[i].dropna()\n"
     ]
    }
   ],
   "source": [
    "aggregate_method = 'concatenate' # can also be 'concatenate'\n",
    "n_bootstrap=1000 ## should be more than 1000 for valid analysis\n",
    "privileged_group = None # if given, fix the priviledged group. If None, the priviledged group will be the group with the best performance (may be different for each metric)\n",
    "ID_col = 'subjIDs'\n",
    "\n",
    "df_improv, df_p_better, df_p_worse =  CV_bootstrap_improvement_test(\n",
    "    dfs_baseline, dfs_corrected, privileged_group=privileged_group, \n",
    "    n_bootstrap=n_bootstrap,aggregate_method=aggregate_method,\n",
    "    ID_col=ID_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>PR</th>\n",
       "      <th>NR</th>\n",
       "      <th>BAcc</th>\n",
       "      <th>FPR</th>\n",
       "      <th>...</th>\n",
       "      <th>PPV_diff</th>\n",
       "      <th>NPV_diff</th>\n",
       "      <th>PR_diff</th>\n",
       "      <th>NR_diff</th>\n",
       "      <th>BAcc_diff</th>\n",
       "      <th>FPR_diff</th>\n",
       "      <th>FNR_diff</th>\n",
       "      <th>OverAllAcc_diff</th>\n",
       "      <th>OverAllAUC_diff</th>\n",
       "      <th>TOTALACC_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensitiveAttr</th>\n",
       "      <th>group_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <th>unspecified</th>\n",
       "      <td>0.328</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <th>unspecified</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AUC    ACC    TPR    TNR    PPV    NPV     PR  \\\n",
       "sensitiveAttr group_type                                                     \n",
       "F             unspecified  0.328  0.167  0.068  0.648  0.313  0.060  0.169   \n",
       "M             unspecified  0.003  0.571  0.792  0.321  0.322  0.631  0.840   \n",
       "\n",
       "                              NR   BAcc    FPR  ...  PPV_diff  NPV_diff  \\\n",
       "sensitiveAttr group_type                        ...                       \n",
       "F             unspecified  0.895  0.199  0.648  ...     0.452     0.085   \n",
       "M             unspecified  0.266  0.455  0.321  ...     0.452     0.085   \n",
       "\n",
       "                           PR_diff  NR_diff  BAcc_diff  FPR_diff  FNR_diff  \\\n",
       "sensitiveAttr group_type                                                     \n",
       "F             unspecified    0.948    0.941      0.229     0.346     0.957   \n",
       "M             unspecified    0.948    0.941      0.229     0.346     0.957   \n",
       "\n",
       "                           OverAllAcc_diff  OverAllAUC_diff  TOTALACC_diff  \n",
       "sensitiveAttr group_type                                                    \n",
       "F             unspecified              1.0              1.0          0.204  \n",
       "M             unspecified              1.0              1.0          0.204  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p_better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HTAN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
