{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some random imorts\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import glob\n",
    "from os.path import basename, dirname,join\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import functions for bootstrap tests\n",
    "from bootstrap_TCGA_improvement_test import CV_bootstrap_improvement_test\n",
    "from bootstrap_TCGA_bias_test import CV_bootstrap_bias_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example CSV files for the results\n",
    "\n",
    "    Each pd.DataFrame contains the following columns:\n",
    "        * sens_attr: sensitive attributes\n",
    "        * prob: model probabilities\n",
    "        * label: ground truth labels\n",
    "        * pred:  model predictions\n",
    "        * [A slide ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_csvs    = [f'bootstrap_example_csvs/baseline/inference_results_fold{i}.csv' for i in range(4)]\n",
    "corrected_csvs   = [f'bootstrap_example_csvs/corrected/inference_results_fold{i}.csv' for i in range(4)]\n",
    "\n",
    "dfs_baseline = [pd.read_csv(csv) for csv in baseline_csvs]\n",
    "dfs_corrected = [pd.read_csv(csv) for csv in corrected_csvs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>logits</th>\n",
       "      <th>prob</th>\n",
       "      <th>file</th>\n",
       "      <th>sens_attr</th>\n",
       "      <th>subjIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.701804</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>M</td>\n",
       "      <td>G-002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.957226</td>\n",
       "      <td>0.123768</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>F</td>\n",
       "      <td>G-005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.703713</td>\n",
       "      <td>0.024040</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>F</td>\n",
       "      <td>G-014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621319</td>\n",
       "      <td>0.349482</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>F</td>\n",
       "      <td>G-019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.343101</td>\n",
       "      <td>0.912384</td>\n",
       "      <td>/n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...</td>\n",
       "      <td>F</td>\n",
       "      <td>G-021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label    logits      prob  \\\n",
       "0           0    0.0  0.855903  0.701804   \n",
       "1           1    1.0 -1.957226  0.123768   \n",
       "2           2    1.0 -3.703713  0.024040   \n",
       "3           3    0.0 -0.621319  0.349482   \n",
       "4           4    1.0  2.343101  0.912384   \n",
       "\n",
       "                                                file sens_attr subjIDs  \n",
       "0  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         M   G-002  \n",
       "1  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         F   G-005  \n",
       "2  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         F   G-014  \n",
       "3  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         F   G-019  \n",
       "4  /n/data2/hms/dbmi/kyu/lab/datasets/MayoBrain/G...         F   G-021  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_baseline[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add binary predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "for df in dfs_baseline:\n",
    "    df['pred'] = df['prob'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "for df in dfs_corrected:\n",
    "    df['pred'] = df['prob'].apply(lambda x: 1 if x > 0.5 else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows without sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_baseline = [df.loc[~df['sens_attr'].isna()] for df in dfs_baseline]\n",
    "dfs_corrected = [df.loc[~df['sens_attr'].isna()] for df in dfs_corrected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for significant bias\n",
    "        df_p_worse:     If the underpriviledged group has lower performance than the priviledged group (for each  performance metric)\n",
    "        df_p_better:    If the underpriviledged group has HIGHER performance than the priviledged group (for each  performance metric)\n",
    "        fairResult:     the original performance & fairnes metrics\n",
    "        df_CI:          The confidence interval of the performance & fairnes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 54.82it/s]\n",
      "100%|██████████| 1000/1000 [00:17<00:00, 58.25it/s]\n",
      "100%|██████████| 1000/1000 [00:18<00:00, 54.63it/s]\n",
      "100%|██████████| 1000/1000 [00:17<00:00, 58.50it/s]\n",
      "100%|██████████| 1000/1000 [00:18<00:00, 54.50it/s]\n",
      "100%|██████████| 1000/1000 [00:17<00:00, 58.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 999 valid bootstrap samples for ENPV. Expected 1000\n",
      "Warning: 999 valid bootstrap samples for EOM(Negative). Expected 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 54.77it/s]\n",
      "100%|██████████| 1000/1000 [00:17<00:00, 58.36it/s]\n",
      "/usr/local/lib/python3.8/dist-packages/scipy/stats/stats.py:7661: RuntimeWarning: divide by zero encountered in log\n",
      "  statistic = -2 * np.sum(np.log(pvalues))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'pvalue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n_bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m \u001b[38;5;66;03m## should be more than 1000 for valid analysis\u001b[39;00m\n\u001b[1;32m      3\u001b[0m privileged_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# if given, fix the priviledged group. If None, the priviledged group will be the group with the best performance (may be different for each metric)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_p_worse_baseline, df_p_better_baseline, fairResult_baseline, df_CI_baseline \u001b[38;5;241m=\u001b[39m  \u001b[43mCV_bootstrap_bias_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdfs_baseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivileged_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bootstrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43maggregate_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregate_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_p_worse_corrected, df_p_better_corrected, fairResult_corrected, df_CI_corrected \u001b[38;5;241m=\u001b[39m  CV_bootstrap_bias_test(\n\u001b[1;32m      7\u001b[0m     dfs_corrected, privileged_group\u001b[38;5;241m=\u001b[39mprivileged_group, n_bootstrap\u001b[38;5;241m=\u001b[39mn_bootstrap,aggregate_method\u001b[38;5;241m=\u001b[39maggregate_method)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# def CV_bootstrap_improvement_test(\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     dfs_baseline, dfs_corrected, privileged_group=None, n_bootstrap=1000,aggregate_method='fisher',add_perf_difference=args.add_perf_difference)\u001b[39;00m\n",
      "File \u001b[0;32m/home/FAIR-Tuning/bootstrap_significant_test/bootstrap_TCGA_bias_test.py:244\u001b[0m, in \u001b[0;36mCV_bootstrap_bias_test\u001b[0;34m(dfs, privileged_group, n_bootstrap, aggregate_method)\u001b[0m\n\u001b[1;32m    242\u001b[0m         pvals \u001b[38;5;241m=\u001b[39m df_p_better[col]\u001b[38;5;241m.\u001b[39mloc[i]\n\u001b[1;32m    243\u001b[0m         meta_res \u001b[38;5;241m=\u001b[39m combine_pvalues(pvals, method\u001b[38;5;241m=\u001b[39maggregate_method, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 244\u001b[0m         df_p_combined[col]\u001b[38;5;241m.\u001b[39mloc[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_res\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpvalue\u001b[49m\n\u001b[1;32m    245\u001b[0m df_p_combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maggregate_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_combined\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    246\u001b[0m df_p_better \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_p_better, df_p_combined])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'pvalue'"
     ]
    }
   ],
   "source": [
    "aggregate_method = 'fisher' # can also be 'concatenate'\n",
    "n_bootstrap=1000 ## should be more than 1000 for valid analysis\n",
    "privileged_group = None # if given, fix the priviledged group. If None, the priviledged group will be the group with the best performance (may be different for each metric)\n",
    "df_p_worse_baseline, df_p_better_baseline, fairResult_baseline, df_CI_baseline =  CV_bootstrap_bias_test(\n",
    "    dfs_baseline, privileged_group=privileged_group, n_bootstrap=n_bootstrap,aggregate_method=aggregate_method)\n",
    "df_p_worse_corrected, df_p_better_corrected, fairResult_corrected, df_CI_corrected =  CV_bootstrap_bias_test(\n",
    "    dfs_corrected, privileged_group=privileged_group, n_bootstrap=n_bootstrap,aggregate_method=aggregate_method)\n",
    "# def CV_bootstrap_improvement_test(\n",
    "#     dfs_baseline, dfs_corrected, privileged_group=None, n_bootstrap=1000,aggregate_method='fisher',add_perf_difference=args.add_perf_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you use fisher, there will be p-values for each fold, plus a combined p-value\n",
    "df_p_worse_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for significant improvement\n",
    "        df_p_better: pd.DataFrame, the p-values for significant improvement\n",
    "        df_p_worse: pd.DataFrame, the p-values for significant worsening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.58it/s]\n",
      "/home/FAIR-Tuning/bootstrap_significant_test/bootstrap_TCGA_improvement_test.py:242: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  bootstrap_values = df_improvement_bootstrap[col].loc[i].dropna()\n",
      "100%|██████████| 1000/1000 [00:43<00:00, 22.96it/s]\n",
      "/home/FAIR-Tuning/bootstrap_significant_test/bootstrap_TCGA_improvement_test.py:242: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  bootstrap_values = df_improvement_bootstrap[col].loc[i].dropna()\n",
      "100%|██████████| 1000/1000 [00:43<00:00, 22.91it/s]\n",
      "/home/FAIR-Tuning/bootstrap_significant_test/bootstrap_TCGA_improvement_test.py:242: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  bootstrap_values = df_improvement_bootstrap[col].loc[i].dropna()\n",
      "100%|██████████| 1000/1000 [00:43<00:00, 23.23it/s]\n",
      "/home/FAIR-Tuning/bootstrap_significant_test/bootstrap_TCGA_improvement_test.py:242: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  bootstrap_values = df_improvement_bootstrap[col].loc[i].dropna()\n",
      "/home/FAIR-Tuning/bootstrap_significant_test/bootstrap_TCGA_improvement_test.py:408: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  pvals = df_p_better[col].loc[i]\n",
      "/usr/local/lib/python3.8/dist-packages/scipy/stats/stats.py:7661: RuntimeWarning: divide by zero encountered in log\n",
      "  statistic = -2 * np.sum(np.log(pvalues))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'pvalue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m privileged_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# if given, fix the priviledged group. If None, the priviledged group will be the group with the best performance (may be different for each metric)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m ID_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjIDs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m df_improv, df_p_better, df_p_worse \u001b[38;5;241m=\u001b[39m  \u001b[43mCV_bootstrap_improvement_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdfs_baseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfs_corrected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivileged_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bootstrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43maggregate_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregate_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mID_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mID_col\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/FAIR-Tuning/bootstrap_significant_test/bootstrap_TCGA_improvement_test.py:410\u001b[0m, in \u001b[0;36mCV_bootstrap_improvement_test\u001b[0;34m(dfs_baseline, dfs_corrected, privileged_group, n_bootstrap, aggregate_method, add_perf_difference, ID_col)\u001b[0m\n\u001b[1;32m    408\u001b[0m         pvals \u001b[38;5;241m=\u001b[39m df_p_better[col]\u001b[38;5;241m.\u001b[39mloc[i]\n\u001b[1;32m    409\u001b[0m         meta_res \u001b[38;5;241m=\u001b[39m combine_pvalues(pvals, method\u001b[38;5;241m=\u001b[39maggregate_method, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 410\u001b[0m         df_p_combined[col]\u001b[38;5;241m.\u001b[39mloc[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_res\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpvalue\u001b[49m\n\u001b[1;32m    411\u001b[0m df_p_combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maggregate_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_combined\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    412\u001b[0m df_p_better \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_p_better, df_p_combined])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'pvalue'"
     ]
    }
   ],
   "source": [
    "aggregate_method = 'fisher' # can also be 'concatenate'\n",
    "n_bootstrap=1000 ## should be more than 1000 for valid analysis\n",
    "privileged_group = None # if given, fix the priviledged group. If None, the priviledged group will be the group with the best performance (may be different for each metric)\n",
    "ID_col = 'subjIDs'\n",
    "\n",
    "df_improv, df_p_better, df_p_worse =  CV_bootstrap_improvement_test(\n",
    "    dfs_baseline, dfs_corrected, privileged_group=privileged_group, \n",
    "    n_bootstrap=n_bootstrap,aggregate_method=aggregate_method,\n",
    "    ID_col=ID_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HTAN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
